{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **-----------------------**>**AI MUSIC GENERATION PROJECT**<**-----------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminal\n",
    "#pip install music21 keras tensorflow mido\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of notes extracted: 11362\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "\n",
    "# Set data path\n",
    "data_path = r\"D:\\# DATA SCIENCE\\# PROJECTS\\- PROJECTS INTERNSHIPS\\CODEALPHA - AI ENGINEERING\\Music Generation with AI Project\\Data\"\n",
    "\n",
    "def get_notes(data_path):\n",
    "    notes = []\n",
    "    \n",
    "    for folder in os.listdir(data_path):\n",
    "        folder_path = os.path.join(data_path, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in glob.glob(os.path.join(folder_path, \"*.mid\")):\n",
    "                midi = converter.parse(file)\n",
    "\n",
    "                notes_to_parse = None\n",
    "                parts = instrument.partitionByInstrument(midi)\n",
    "                \n",
    "                if parts:  # File has instrument parts\n",
    "                    notes_to_parse = parts.parts[0].recurse()\n",
    "                else:  # File has flat notes\n",
    "                    notes_to_parse = midi.flat.notes\n",
    "                \n",
    "                for element in notes_to_parse:\n",
    "                    if isinstance(element, note.Note):\n",
    "                        notes.append(str(element.pitch))\n",
    "                    elif isinstance(element, chord.Chord):\n",
    "                        notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return notes\n",
    "\n",
    "# Get all notes from the dataset\n",
    "notes = get_notes(data_path)\n",
    "print(f\"Number of notes extracted: {len(notes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data for the Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Get all unique notes\n",
    "unique_notes = list(set(notes))\n",
    "n_vocab = len(unique_notes)\n",
    "\n",
    "# Map notes to integers\n",
    "note_to_int = {note: i for i, note in enumerate(unique_notes)}\n",
    "int_notes = [note_to_int[note] for note in notes]\n",
    "\n",
    "# Prepare sequences of notes for training\n",
    "sequence_length = 100\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "for i in range(0, len(int_notes) - sequence_length):\n",
    "    seq_in = int_notes[i:i + sequence_length]\n",
    "    seq_out = int_notes[i + sequence_length]\n",
    "    \n",
    "    network_input.append(seq_in)\n",
    "    network_output.append(seq_out)\n",
    "\n",
    "n_patterns = len(network_input)\n",
    "\n",
    "# Reshape for LSTM model (RNN)\n",
    "network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "network_input = network_input / float(n_vocab)\n",
    "\n",
    "# One-hot encode the output\n",
    "network_output = to_categorical(network_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 512)          1052672   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 512)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 512)               2099200   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 222)               57054     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 222)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3340254 (12.74 MB)\n",
      "Trainable params: 3340254 (12.74 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the LSTM Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "176/176 [==============================] - 298s 2s/step - loss: 4.8576\n",
      "Epoch 2/10\n",
      "176/176 [==============================] - 443s 3s/step - loss: 4.7862\n",
      "Epoch 3/10\n",
      "176/176 [==============================] - 451s 3s/step - loss: 4.8013\n",
      "Epoch 4/10\n",
      "176/176 [==============================] - 449s 3s/step - loss: 4.7598\n",
      "Epoch 5/10\n",
      "176/176 [==============================] - 445s 3s/step - loss: 4.7495\n",
      "Epoch 6/10\n",
      "176/176 [==============================] - 448s 3s/step - loss: 4.7461\n",
      "Epoch 7/10\n",
      "176/176 [==============================] - 446s 3s/step - loss: 4.7441\n",
      "Epoch 8/10\n",
      "176/176 [==============================] - 441s 3s/step - loss: 4.7409\n",
      "Epoch 9/10\n",
      "176/176 [==============================] - 447s 3s/step - loss: 4.7396\n",
      "Epoch 10/10\n",
      "176/176 [==============================] - 442s 3s/step - loss: 4.7411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21d9540b550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model\n",
    "model.fit(network_input, network_output, epochs=10, batch_size=64)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file test_output_0.mid saved.\n",
      "MIDI file test_output_1.mid saved.\n",
      "MIDI file test_output_2.mid saved.\n",
      "MIDI file test_output_3.mid saved.\n",
      "MIDI file test_output_4.mid saved.\n"
     ]
    }
   ],
   "source": [
    "# Generate Music\n",
    "import random\n",
    "\n",
    "def generate_music(model, network_input, int_to_note, n_vocab, output_length=500, temperature=1.0):\n",
    "    start = np.random.randint(0, len(network_input) - 1)\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # Generate output_length notes\n",
    "    for _ in range(output_length):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "        prediction = np.log(prediction + 1e-6) / temperature\n",
    "        prediction = np.exp(prediction)\n",
    "        prediction = prediction / np.sum(prediction)\n",
    "        index = np.random.choice(range(n_vocab), p=prediction[0])\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern = np.append(pattern, index)\n",
    "        pattern = pattern[1:]\n",
    "\n",
    "    return prediction_output\n",
    "\n",
    "# Map integers back to notes\n",
    "int_to_note = {i: note for note, i in note_to_int.items()}\n",
    "\n",
    "# Generate and save multiple pieces of music\n",
    "def create_midi(prediction_output, output_file):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    for pattern in prediction_output:\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                note_obj = note.Note(int(current_note))\n",
    "                note_obj.storedInstrument = instrument.Piano()\n",
    "                notes.append(note_obj)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        offset += np.random.uniform(0.5, 1.0)  # Randomize offset\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp=output_file)\n",
    "\n",
    "for i in range(5):  # Generate 5 different pieces\n",
    "    predicted_notes = generate_music(model, network_input, int_to_note, n_vocab, output_length=500, temperature=1.0)\n",
    "    output_file = f'test_output_{i}.mid'\n",
    "    create_midi(predicted_notes, output_file)\n",
    "    print(f\"MIDI file {output_file} saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('music_generation_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('music_generation_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & Generate a New Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New MIDI file D:\\# DATA SCIENCE\\# PROJECTS\\- PROJECTS INTERNSHIPS\\CODEALPHA - AI ENGINEERING\\Music Generation with AI Project\\Generated Music\\new_song_20240926_044925.mid saved to D:\\# DATA SCIENCE\\# PROJECTS\\- PROJECTS INTERNSHIPS\\CODEALPHA - AI ENGINEERING\\Music Generation with AI Project\\Generated Music.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "# Path to the folder where you want to save the generated music files\n",
    "save_path = r'D:\\# DATA SCIENCE\\# PROJECTS\\- PROJECTS INTERNSHIPS\\CODEALPHA - AI ENGINEERING\\Music Generation with AI Project\\Generated Music'\n",
    "\n",
    "# Ensure the folder exists, create it if it doesn't\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Regenerate a new piece of music\n",
    "predicted_notes = generate_music(model, network_input, int_to_note, n_vocab, output_length=500, temperature=1.0)\n",
    "\n",
    "# Generate a unique filename using the current timestamp\n",
    "output_file = os.path.join(save_path, f'new_song_{time.strftime(\"%Y%m%d_%H%M%S\")}.mid')\n",
    "\n",
    "# Save the MIDI file with the unique filename in the specified folder\n",
    "create_midi(predicted_notes, output_file)\n",
    "print(f\"New MIDI file {output_file} saved to {save_path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
